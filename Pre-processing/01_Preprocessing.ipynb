{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **IMC data processing pipeline**\n",
    " \n",
    "This pipeline has been specifically developed for the Imaging Mass Cytometry (IMC) - Type 1 Diabetes (T1D) project.\n",
    " \n",
    "## **Introduction**\n",
    " \n",
    "This pipeline extracts image data from Imaging Mass Cytometry aquisitions, performs islet- and cell-level image segmentation and extracts measurements from the segmented objects.  \n",
    "This pipeline is designed to work with two antibody panels applied to two consecutive tissue sections.\n",
    "\n",
    "As input, the user should provide zipped folders containing IMC acquisition (one `.mcd` file with the associated `.txt` files), and a panel file (`panel.csv`) for each antibody panel that indicates the channels that were measured and the channels that should be used for segmentation. Detailed information about zipped folders and panel files can be found below.\n",
    " \n",
    "This pipeline is based on functions from the [steinbock package](https://github.com/BodenmillerGroup/steinbock), full steinbock documentation can be found here: https://bodenmillergroup.github.io/steinbock.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# # **IMC data processing pipeline**\n",
    "# \n",
    "# This pipeline has been specifically developed for the Imaging Mass Cytometry (IMC) - Type 1 Diabetes (T1D) project.\n",
    "# \n",
    "# ## **Introduction**\n",
    "# \n",
    "# This pipeline extracts image data from Imaging Mass Cytometry aquisitions, performs islet- and cell-level image segmentation and extracts measurements from the segmented objects.  \n",
    "# This pipeline is designed to work with two antibody panels applied to two consecutive tissue sections.\n",
    "# \n",
    "# As input, the user should provide zipped folders containing IMC acquisition (one `.mcd` file with the associated `.txt` files), and a panel file (`panel.csv`) for each antibody panel that indicates the channels that were measured and the channels that should be used for segmentation. Detailed information about zipped folders and panel files can be found below.\n",
    "# \n",
    "# This pipeline is based on functions from the [steinbock package](https://github.com/BodenmillerGroup/steinbock), full steinbock documentation can be found here: https://bodenmillergroup.github.io/steinbock.\n",
    "\n",
    "# # **Preprocessing**\n",
    "# \n",
    "# ## **Configuration**\n",
    "# \n",
    "# ### **Import packages**\n",
    "\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from steinbock import io\n",
    "from steinbock.preprocessing import imc\n",
    "\n",
    "\n",
    "print(sys.path)\n",
    "print(sys.executable)\n",
    "\n",
    "### Helper functions\n",
    "\n",
    "# Helper functions to get unique elements from 2 lists with elements of list 1 having .tiff suffixes.\n",
    "def get_unique_elements(list1, list2):\n",
    "    # Include some \" - split here\"\n",
    "    return [element for element in list1 if not any(element.replace(\" - split.tiff\", \"\").replace(\".tiff\", \"\") in item for item in list2)]\n",
    "\n",
    "# Helper function to get all duplicates in 2 lists.\n",
    "def get_duplicates(lst):\n",
    "    unique_elements = set()\n",
    "    duplicates = []\n",
    "    for item in lst:\n",
    "        if item in unique_elements:\n",
    "            duplicates.append(item)\n",
    "        else:\n",
    "            unique_elements.add(item)\n",
    "    \n",
    "    return duplicates\n",
    "\n",
    "\n",
    "# ### **Define input and output directories**\n",
    "# \n",
    "# *Manual step:* enter the path to the directory where the data will be saved (named `folder_data` from here on).\n",
    "\n",
    "# Data folder\n",
    "folder_data = Path(\"/home/processing/\")\n",
    "Path(folder_data).mkdir(parents=True, exist_ok=True)\n",
    "assert Path.exists(folder_data), f\"{folder_data} does not exist\"\n",
    "print(\"Data folder:\", folder_data)\n",
    "\n",
    "# Git folder (folder containing the current notebook)\n",
    "folder_git = Path.cwd()\n",
    "assert Path.exists(folder_git), f\"{folder_git} does not exist\"\n",
    "print(\"Git folder:\", folder_git)\n",
    "\n",
    "\n",
    "# #### **Create folders for intermediate processing steps**\n",
    "# - `raw`: should contain user-provided zipped `.mcd` and `.txt` acquisitions.\n",
    "# - `img`: store extracted images in `.tiff` format.\n",
    "# - `seg_cells`: store image stacks for cell segmentation.\n",
    "# - `seg_islets`: store image stacks for islet segmentation.\n",
    "# - `masks_cells`: store cell segmentation masks.\n",
    "# - `masks_islets`: store islet segmentation masks.\n",
    "# - `data_cells`: store generated single cell-level data.\n",
    "# - `data_islets`: store generated islet-level data.\n",
    "\n",
    "folders = {\n",
    "    \"raw\": folder_data / \"raw\",\n",
    "    \"img\": folder_data / \"img\",\n",
    "    \"seg_cells\": folder_data / \"seg_cells\",\n",
    "    \"seg_islets\": folder_data / \"seg_islets\",\n",
    "    \"masks_cells\": folder_data / \"masks_cells\",\n",
    "    \"masks_islets\": folder_data / \"masks_islets\",\n",
    "    \"data_cells\": folder_data / \"data_cells\",\n",
    "    \"data_islets\": folder_data / \"data_islets\",\n",
    "    \"variables\": folder_data / \"variables\"\n",
    "}\n",
    "# Make directories (if they do not exist)\n",
    "for folder in folders.values():\n",
    "    folder.mkdir(exist_ok=True)\n",
    "    \n",
    "# Add base previously defined data and git folders\n",
    "folders[\"data\"] = folder_data\n",
    "folders[\"git\"] = folder_git\n",
    "\n",
    "# Export folder names for use in downstream notebooks\n",
    "with open(folder_data / \"variables\" / \"folders.txt\", \"wb\") as handle:\n",
    "    pickle.dump(folders, handle)\n",
    "\n",
    "\n",
    "# ### **Antibody panels**\n",
    "# \n",
    "# Panel files are user-provided `.csv` files that should be located in `folder_data` and contain the following columns:\n",
    "# - `channel`: unique channel ID.\n",
    "# - `metal`: metal isotope to which the antibody is conjugated (format: `Nd144`, `Ir191`).\n",
    "# - `name`: name of the target marker.\n",
    "# - `keep` should the channel be retained for processing and analysis? (1 = yes, 0 = no).\n",
    "# - `deepcell` should the channel be used for cell segmentation and in which compartment the marker is expressed? (1 = nucleus, 2 = membrane, empty if the channel should not be used).\n",
    "# - `isletseg` should the channel be used for islet segmentation? (1 = yes, empty = channel not used).\n",
    "\n",
    "# Columns required in the panel file(s)\n",
    "panel_cols = {\n",
    "    \"col_channel\": \"channel\",\n",
    "    \"col_metal\": \"metal\",\n",
    "    \"col_name\": \"name\",\n",
    "    \"col_keep\": \"keep\",\n",
    "    \"col_deeepcell\": \"deepcell\",\n",
    "    \"col_islet_seg\": \"isletseg\"\n",
    "}\n",
    "\n",
    "\n",
    "# *Manual step:* adapt the panel names and panel file names if needed. \n",
    "\n",
    "# List panel files\n",
    "panels = {\n",
    "    \"Islet\": (folder_data / 'panel_Islet.csv'),\n",
    "    \"Immune\": (folder_data / 'panel_Immune.csv')\n",
    "}\n",
    "\n",
    "\n",
    "# #### **Load and display the panels**\n",
    "\n",
    "# Loop through the panels\n",
    "for panel_name, panel_path in panels.items():\n",
    "    print(\"Panel:\", panel_name)\n",
    "    \n",
    "    # Load the panel file\n",
    "    assert Path.exists(panel_path), f\"{panel_path} does not exist\"\n",
    "    cur_panel = pd.read_csv(panel_path, sep = ',', index_col = False)\n",
    "\n",
    "    # Make sure that the required columns exist\n",
    "    for col in panel_cols.values():\n",
    "        assert(col in cur_panel.columns), f\"Column {col} missing from panel\"\n",
    "    \n",
    "    # Subset the panel\n",
    "    cur_panel = cur_panel[cur_panel[panel_cols[\"col_keep\"]]==1]\n",
    "    panels[panel_name] = cur_panel\n",
    "    \n",
    "    # Display the panel\n",
    "    print(panels[panel_name].head())\n",
    "    \n",
    "# Export the panels for use in downstream scripts\n",
    "with open(folder_data / \"variables\" / \"panels.txt\", \"wb\") as handle:\n",
    "     pickle.dump(panels, handle)\n",
    "\n",
    "\n",
    "# ## **Process zipped folders**\n",
    "# \n",
    "# IMC acquisitions generate `.mcd` and `.txt` files. Each acquisition session (corresponding ot one `.mcd` file) should be zipped in a folder containing:\n",
    "# - The `.mcd` file.\n",
    "# - All the associated `.txt` files generated during the acquisition (do not change any of the file names).\n",
    "# The `.txt` files are used as a backup in case the data cannot be extracted from the `.mcd` file.\n",
    "# \n",
    "# All the zipped folders should be stored in subfolders of the `raw` folder (in the `folder_data` directory). The subfolders should be named exactly like the panels in `panels` (see \"List panel files\" above).  \n",
    "# \n",
    "# For the current dataset, the folder structure is the following, with zipped MCD and TXT files stored in `raw/Immune` and `raw/Islet`:\n",
    "#folder_data\n",
    "#|_ data_cells\n",
    "#|_ data_islets\n",
    "#|_ img\n",
    "#|_ masks_cells\n",
    "#|_ masks_islets\n",
    "#|_ raw\n",
    "#    |_ Immune <- ZIP files from the Immune panel stored here\n",
    "#    |_ Islet  <- ZIP files from the Islet panel stored here\n",
    "#|_ seg_cells\n",
    "#|_ seg_islets\n",
    "#|\n",
    "#|_ panel_Immune.csv <- Panel file (Immune panel)\n",
    "#|_ panel_Islet.csv  <- Panel file (Islet panel)\n",
    "# ### **List `.zip` folders**\n",
    "# *Manual step:* define a regular expression to identify the naming scheme of `.zip` files.\n",
    "\n",
    "# Part that all zipped files need to have in common\n",
    "file_regex = '(?P<caseid>[0-9]{3,4})_(?P<panel>[a-zA-Z0-9]{5,6})*'\n",
    "\n",
    "\n",
    "# List all zip folders that match the regular expression.\n",
    "\n",
    "# List zip folders. This should 190 folders.\n",
    "re_fn = re.compile(file_regex)\n",
    "zip_folders = [f for f in folders['raw'].rglob(\"*\") if \n",
    "               re.match(file_regex, f.name)]\n",
    "print(\"\\nTotal number of '.zip' folders:\", len(zip_folders))\n",
    "\n",
    "# List all case IDs and panels\n",
    "case_list = []\n",
    "panel_list = []\n",
    "\n",
    "for file in zip_folders:\n",
    "    case_list.append(re_fn.search(file.name).group(\"caseid\"))\n",
    "    panel_list.append(re_fn.search(file.name).group(\"panel\"))\n",
    "\n",
    "case_list = set(case_list)\n",
    "panel_list = set(panel_list)\n",
    "\n",
    "# Generate a table with case IDs as indexes and panels as columns\n",
    "zip_table = pd.DataFrame(dtype=str, columns=panel_list, index=case_list)\n",
    "\n",
    "for file in zip_folders:\n",
    "    cur_case = re_fn.search(file.name).group(\"caseid\")\n",
    "    cur_panel = re_fn.search(file.name).group(\"panel\")\n",
    "    zip_table.loc[cur_case, cur_panel] = file.name\n",
    "zip_table\n",
    "\n",
    "\n",
    "# ## **Extract images from IMC acquisitions**\n",
    "# \n",
    "# Here, images are extracted from raw IMC files and saved in the `img` folder. Each image corresponds to one acquisition in one file, with the image channels filtered (`keep` column in antibody panel) and sorted according to the the panel file.  \n",
    "# \n",
    "# In case an `.mcd` file is corrupted, the steinbock function tries to extract missing acquisitions from matching `.txt` files. In a second step, images from unmatched `.txt` files are extracted as well.  \n",
    "# \n",
    "# See the full documentation here: https://bodenmillergroup.github.io/steinbock/latest/cli/preprocessing/#image-conversion\n",
    "# \n",
    "# ### **Settings**\n",
    "# After image extraction, hot pixel filtering is performed using the threshold defined by the `hot_pixel_filtering` variable.\n",
    "\n",
    "hot_pixel_filtering = 50\n",
    "\n",
    "\n",
    "# ### **Fix mismatched regions**\n",
    "# Due to an issue with region selection, the regions of interest (ROI) acquired on consecutive sections were mismatched (i.e., had different acquisition numbers) for a three of the 95 measured samples.  \n",
    "# Here, we use manually-generated dictionaries to re-map the ROI numbers of the *Immune* panel, so that they correspond to the numbers of the *Islet* panel.\n",
    "\n",
    "mismatched_cases = (\"6043\", \"6048\", \"6429\")\n",
    "\n",
    "map_dict = [\n",
    "    {\"name\": \"6043\",\n",
    "     \"001\": \"074\", \"002\": \"055\", \"003\": \"059\", \"004\": \"035\", \"005\": \"003\", \"006\": \"023\", \"007\": \"010\", \"008\": \"008\", \"009\": \"021\", \"010\": \"052\",\n",
    "     \"011\": \"049\", \"012\": \"012\", \"013\": \"053\", \"014\": \"028\", \"015\": \"018\", \"016\": \"048\", \"017\": \"017\", \"018\": \"026\", \"019\": \"065\", \"020\": \"046\", \n",
    "     \"021\": \"068\", \"022\": \"016\", \"023\": \"054\", \"024\": \"063\", \"025\": \"025\", \"026\": \"073\", \"027\": \"042\", \"028\": \"007\", \"029\": \"044\", \"030\": \"027\",\n",
    "     \"031\": \"005\", \"032\": \"031\", \"033\": \"014\", \"034\": \"020\", \"035\": \"064\", \"036\": \"036\", \"037\": \"039\", \"038\": \"076\", \"039\": \"061\", \"040\": \"050\", \n",
    "     \"041\": \"032\", \"042\": \"066\", \"043\": \"029\", \"044\": \"037\", \"045\": \"070\", \"046\": \"019\", \"047\": \"047\", \"048\": \"033\", \"049\": \"009\", \"050\": \"067\", \n",
    "     \"051\": \"051\", \"052\": \"011\", \"053\": \"006\", \"054\": \"043\", \"055\": \"001\", \"056\": \"022\", \"057\": \"034\", \"058\": \"062\", \"059\": \"045\", \"060\": \"058\", \n",
    "     \"061\": \"060\", \"062\": \"002\", \"063\": \"071\", \"064\": \"038\", \"065\": \"075\", \"066\": \"041\", \"067\": \"056\", \"068\": \"072\", \"069\": \"069\", \"070\": \"040\", \n",
    "     \"071\": \"013\", \"072\": \"057\", \"073\": \"004\", \"074\": \"030\", \"075\": \"015\", \"076\": \"024\"},\n",
    "    {\"name\": \"6048\",\n",
    "     \"001\": \"001\", \"002\": \"067\", \"003\": \"034\", \"004\": \"052\", \"005\": \"005\", \"006\": \"030\", \"007\": \"055\", \"008\": \"007\", \"009\": \"063\", \"010\": \"010\",\n",
    "     \"011\": \"011\", \"012\": \"025\", \"013\": \"013\", \"014\": \"014\", \"015\": \"015\", \"016\": \"019\", \"017\": \"021\", \"018\": \"058\", \"019\": \"020\", \"020\": \"032\", \n",
    "     \"021\": \"045\", \"022\": \"002\", \"023\": \"023\", \"024\": \"024\", \"025\": \"047\", \"026\": \"018\", \"027\": \"027\", \"028\": \"028\", \"029\": \"056\", \"030\": \"008\", \n",
    "     \"031\": \"078\", \"032\": \"057\", \"033\": \"068\", \"034\": \"022\", \"035\": \"035\", \"036\": \"036\", \"037\": \"037\", \"038\": \"051\", \"039\": \"004\", \"040\": \"040\", \n",
    "     \"041\": \"033\", \"042\": \"042\", \"043\": \"043\", \"044\": \"050\", \"045\": \"054\", \"046\": \"046\", \"047\": \"075\", \"048\": \"048\", \"049\": \"049\", \"050\": \"016\", \n",
    "     \"051\": \"060\", \"052\": \"029\", \"053\": \"053\", \"054\": \"039\", \"055\": \"009\", \"056\": \"006\", \"057\": \"003\", \"058\": \"038\", \"059\": \"059\", \"060\": \"017\", \n",
    "     \"061\": \"061\", \"062\": \"062\", \"063\": \"065\", \"064\": \"064\", \"065\": \"071\", \"066\": \"066\", \"067\": \"069\", \"068\": \"073\", \"069\": \"012\", \"070\": \"070\", \n",
    "     \"071\": \"026\", \"072\": \"072\", \"073\": \"044\", \"074\": \"074\", \"075\": \"031\", \"076\": \"076\", \"077\": \"077\", \"078\": \"041\"},\n",
    "    {\"name\": \"6429\",\n",
    "     \"001\": \"023\", \"002\": \"056\", \"003\": \"017\", \"004\": \"040\", \"005\": \"013\", \"006\": \"053\", \"007\": \"079\", \"008\": \"073\", \"009\": \"036\", \"010\": \"051\", \n",
    "     \"011\": \"021\", \"012\": \"068\", \"013\": \"070\", \"014\": \"081\", \"015\": \"077\", \"016\": \"066\", \"017\": \"054\", \"018\": \"072\", \"019\": \"041\", \"020\": \"047\", \n",
    "     \"021\": \"033\", \"022\": \"008\", \"023\": \"063\", \"024\": \"042\", \"025\": \"014\", \"026\": \"022\", \"027\": \"045\", \"028\": \"061\", \"029\": \"009\", \"030\": \"004\", \n",
    "     \"031\": \"059\", \"032\": \"052\", \"033\": \"067\", \"034\": \"035\", \"035\": \"028\", \"036\": \"024\", \"037\": \"032\", \"038\": \"071\", \"039\": \"062\", \"040\": \"055\",\n",
    "     \"041\": \"030\", \"042\": \"038\", \"043\": \"050\", \"044\": \"043\", \"045\": \"007\", \"046\": \"074\", \"047\": \"019\", \"048\": \"039\", \"049\": \"020\", \"050\": \"064\", \n",
    "     \"051\": \"058\", \"052\": \"076\", \"053\": \"002\", \"054\": \"075\", \"055\": \"011\", \"056\": \"029\", \"057\": \"044\", \"058\": \"001\", \"059\": \"012\", \"060\": \"069\", \n",
    "     \"061\": \"026\", \"062\": \"078\", \"063\": \"057\", \"064\": \"031\", \"065\": \"049\", \"066\": \"010\", \"067\": \"005\", \"068\": \"018\", \"069\": \"046\", \"070\": \"003\",\n",
    "     \"071\": \"037\", \"072\": \"080\", \"073\": \"027\", \"074\": \"065\", \"075\": \"048\", \"076\": \"015\", \"077\": \"016\", \"078\": \"025\", \"079\": \"006\", \"080\": \"060\", \n",
    "     \"081\": \"034\"}\n",
    "]\n",
    "\n",
    "\n",
    "# ### **Image conversion**\n",
    "# Extract image stacks from IMC acquisitions. \n",
    "# Image and acquisition metadata are exported to `folder_data` as `images.csv`.\n",
    "\n",
    "panels[\"Islet\"]\n",
    "\n",
    "for panel_name, panel in panels.items():\n",
    "    print(\"Processing\", panel_name, \"panel\")\n",
    "    \n",
    "    # Input and output folders\n",
    "    image_info = []\n",
    "    raw_subdir = folders[\"raw\"] / panel_name\n",
    "    img_subdir = folders[\"img\"] / panel_name\n",
    "    img_subdir.mkdir(exist_ok = True)  \n",
    "    \n",
    "    # List zipped files\n",
    "    cur_mcd_files = imc.list_mcd_files(raw_subdir, unzip=True)\n",
    "    cur_txt_files = imc.list_txt_files(raw_subdir, unzip=True)\n",
    "    \n",
    "    # Process files\n",
    "    for (mcd_file, acquisition, img, matched_txt, recovered) in \\\n",
    "    imc.try_preprocess_images_from_disk(\n",
    "        cur_mcd_files, cur_txt_files,\n",
    "        hpf = hot_pixel_filtering,\n",
    "        channel_names = panels[panel_name][\"metal\"],\n",
    "        unzip = True\n",
    "    ):\n",
    "        cur_desc = acquisition.description\n",
    "        cur_case = re_fn.search(mcd_file.name).group(\"caseid\")\n",
    "        \n",
    "        # Renumber mismatched images\n",
    "        if (panel_name == \"Immune\" and cur_case in mismatched_cases):\n",
    "            cur_dict = next(item for item in map_dict if item[\"name\"] == cur_case)\n",
    "            cur_desc = cur_desc[:-3] + cur_dict.get(cur_desc[-3:])\n",
    "            \n",
    "        img_file = f\"{mcd_file.stem}_{cur_desc}.tiff\"\n",
    "        io.write_image(img, img_subdir / img_file)\n",
    "\n",
    "        # Save acquisition metadata\n",
    "        image_info_row = imc.create_image_info(\n",
    "            mcd_file, acquisition, img, matched_txt, recovered, img_file\n",
    "        )\n",
    "        \n",
    "        # Renumber mismatched images in image metadta file\n",
    "        if (panel_name == \"Immune\" and cur_case in mismatched_cases):\n",
    "            image_info_row[\"acquisition_description\"] = cur_desc\n",
    "        \n",
    "        image_info_row[\"panel\"] = panel_name\n",
    "        image_info.append(image_info_row)\n",
    "\n",
    "    image_info = pd.DataFrame(image_info)\n",
    "    image_meta_file = f\"images_{panel_name}.csv\"\n",
    "    image_info.to_csv(folders[\"data\"] / image_meta_file, index = False)\n",
    "\n",
    "\n",
    "# ## **Catch unmatched images**\n",
    "# \n",
    "# ### **Flag missing images**\n",
    "# The ablated regions should be the same on all consecutive sections. Here, we attempt to match images from different panels, based on the ROI number. Images from one panel that do not have a corresponding image in the other panel(s) are flagged.\n",
    "\n",
    "panel_names = list(panels.keys())\n",
    "missing = set()\n",
    "\n",
    "# List files for the first panel\n",
    "images_panel0 = sorted([img.name.replace(panel_names[0], \"\") \\\n",
    "                        for img in Path.iterdir(folders[\"img\"] / panel_names[0])])\n",
    "images_panel0 = frozenset(images_panel0)\n",
    "\n",
    "# Find matched images in the other panels\n",
    "for panel_name in panel_names[1:]:\n",
    "    cur_images = [img.name for img in Path.iterdir(folders[\"img\"] / panel_name)]\n",
    "    cur_list = set([img.replace(panel_name, \"\") for \\\n",
    "                    img in cur_images])\n",
    "    \n",
    "    missing.add(frozenset(images_panel0.difference(cur_list)))\n",
    "    missing.add(frozenset(cur_list.difference(images_panel0)))\n",
    "\n",
    "# Print out all missing images\n",
    "missing = [list(x) for x in missing]\n",
    "missing = sorted([x for xs in missing for x in xs])\n",
    "print(\"Images with missing corresponding images (\", len(missing),\n",
    "      \"missing images ):\\n\", missing)\n",
    "\n",
    "\n",
    "# ### **Rescue split images**\n",
    "# \n",
    "# Sometimes the laser stopped to ablate during acquisition. After restart, two split .txt-files were outputted. Here, split acquisitions which fully contain the Islet are retained (`keep_files`). \n",
    "# \n",
    "# Acquisitions, which splitted the islet are deleted below.\n",
    "\n",
    "# These acquisitions were split but will be retained as Islet is visible in acquisitions.\n",
    "keep_files = ['6547_Immune_ROI_046','6520_Immune_ROI_032', '6289_Immune_ROI_034', \\\n",
    "                '6147_Immune_ROI_011', '6538_Islet_ROI_055']\n",
    "\n",
    "it = []\n",
    "\n",
    "# Iterate through panels.\n",
    "for panel_name in panel_names:\n",
    "    cur_images = [img for img in Path.iterdir(folders[\"img\"] / panel_name)]\n",
    "\n",
    "    # Paths of split top and split bottom .tiffs\n",
    "    # Example: split bottom: 6520_Immune_ROI_032 - split.tiff\n",
    "    # Example: split top: 6520_Immune_ROI_032.tiff\n",
    "    spl_top = [img for img in cur_images for file in keep_files if file in str(img.with_suffix(\"\").name)]\n",
    "    spl_bottom = [Path(re.sub(r\" - split.tiff\", \".tiff\", string = str(x))) for x in spl_top]\n",
    "    dict_paths = dict(zip(spl_top, spl_bottom))\n",
    "    \n",
    "    # used to update \"missing\" list \n",
    "    not_missing = [im.with_suffix(\"\").name.replace((\"_\" + panel_name + \"_\"), \"__\") for im in spl_bottom]\n",
    "    it.extend(get_unique_elements(missing, not_missing))\n",
    "    \n",
    "    # Delete split .tiff not containing Islet.\n",
    "    # Replace file name if \"- split.tiff\" contains file name.\n",
    "    for key, value in dict_paths.items():\n",
    "        # Keep bottom split file.\n",
    "        key.replace(value)\n",
    "            \n",
    "# Updated missing list\n",
    "missing = get_duplicates(it)\n",
    "print(\"Images with missing corresponding images (\", len(missing),\n",
    "      \"updated missing images ):\\n\", missing)\n",
    "\n",
    "\n",
    "# List files for the Islet panel\n",
    "images_panel0 = sorted([img.name.replace(panel_names[0], \"\") \\\n",
    "                        for img in Path.iterdir(folders[\"img\"] / panel_names[0])])\n",
    "images_panel0 = frozenset(images_panel0)\n",
    "images_panel0\n",
    "\n",
    "# List files for the Immune panel\n",
    "for panel_name in panel_names[1:]:\n",
    "    cur_images = [img.name for img in Path.iterdir(folders[\"img\"] / panel_name)]\n",
    "    cur_list = set([img.replace(panel_name, \"\") for img in cur_images])\n",
    "    print(cur_list)\n",
    "\n",
    "\n",
    "# ### **Delete unmatched images**\n",
    "# \n",
    "# Images that do not have a matching image in all the other panels are deleted.\n",
    "\n",
    "delete_unmatched_images = True\n",
    "\n",
    "if missing and delete_unmatched_images:\n",
    "    for panel_name in panel_names:\n",
    "        cur_dir = folders[\"img\"] / panel_name\n",
    "        unmatched_images = [\n",
    "            cur_dir / im.replace(\"__\", (\"_\" + panel_name + \"_\")) \\\n",
    "            for im in missing]\n",
    "        \n",
    "        for image in unmatched_images:\n",
    "            print(f\"Deleting {image}\")\n",
    "            Path.unlink(image, missing_ok=True)\n",
    "\n",
    "\n",
    "# ## **Next steps**\n",
    "# \n",
    "# The next step in this pipeline is islet segmentation, which is performed with the `02_IsletSegmentation.ipynb` notebook.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
